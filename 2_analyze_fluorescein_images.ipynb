{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze fluorescein images\n",
    "#### Implementation notes\n",
    "- If there are issues running MultiTracker check to see if it is in conflict with OpenCV2. If so, edit your `.bashrc` file to change the PATH from ros to conda while running this script only. Make sure to run `source ~/.bashrc` to update your changes. \n",
    "\n",
    "#### List of tasks accomplished in this Jupyter Notebook:\n",
    "- Examine experimental image to see which encoding best captures differences in color\n",
    "- Bin experimental photographs into 1mm x 1mm segments. This is done to normalize between photos that are a different number of pixels wide. Each bin is represented by the mean saturation value (S) of all pixels within that 1mm x 1mm segment. Save these reduced data files into a new folder. \n",
    "- Subtract the Saturation value in the blank image from the corresponding experiment image for each experiment series. This is done to correct for potential differences in lighting between photographs or experiments. \n",
    "- Similarly, subtract the Saturation value in the blank image from the corresponding experiment image for each standardization image. \n",
    "- Combine the data from all 1mm x 1mm cells for all standardization images into a single file\n",
    "- Create a master dataframe of statistics for the standardization dataset\n",
    "- Create a threshold of concentration for the experimental dataset to use as the 100% dye value \n",
    "- Create a linear interpolation between color (HSV saturation) and concentration using the reference dataset\n",
    "- Use the interpolation between color and concentration to map each experimental saturation value to concentration\n",
    "- Average the concentration calculations for every time unit (1min, 2min, etc) across all 10 experiments with larvae \n",
    "- Average the concentration calculations for every time unit across all 10 experiments without larvae \n",
    "- Create a master dataframe containing the concentration in each bin across all 15 minutes\n",
    "- Create a file containing distances of all bins from the odor source for experiments with larvae (for use in computational modeling)\n",
    "- Create files to analyze differences in diffusion between experiments with and without larvae\n",
    "- Fit an exponential line to the distance and concentration dataset for modeling purposes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2, glob\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.interpolate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Examine all experimental images to see which encoding best captures differences in color\n",
    "\n",
    "*Result:* The saturation channel from HSV captured the greatest variance in color (range of values is highest). Therefore this channel was used in all subsequent analyses to represent color as a single value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = glob.glob(\"./data/fluorescein/experiments/*-experiment*/crop_experiments/*.jpg\")\n",
    "print(len(names), \"files to include in analysis dataset\")\n",
    "\n",
    "color_dict = {\"filename\":[],\"R\":[],\"G\":[],\"B\":[],\"H\":[],\"S\":[],\"V\":[]}\n",
    "labels = [\"R\", \"G\", \"B\", \"H\", \"S\", \"V\"]\n",
    "    \n",
    "for name in names:\n",
    "    test_image = cv2.imread(name)\n",
    "    b = test_image[:,:,0]\n",
    "    g = test_image[:,:,1]\n",
    "    r = test_image[:,:,2]\n",
    "\n",
    "    hsv = cv2.cvtColor(test_image, cv2.COLOR_BGR2HSV)\n",
    "    h = hsv[:,:,0]\n",
    "    s = hsv[:,:,1]\n",
    "    v = hsv[:,:,2]\n",
    "    \n",
    "    colors = [r, g, b, h, s, v]\n",
    "    color_dict[\"filename\"].append(name.split(\"/\")[-1].split(\"\\\\\")[-1])\n",
    "    \n",
    "    for label, color in zip(labels, colors):\n",
    "        colrange = max(color.flatten()) - min(color.flatten())\n",
    "        color_dict[label].append(colrange)\n",
    "\n",
    "# Save the results in a CSV file \n",
    "df = pd.DataFrame.from_dict(color_dict)\n",
    "df.to_csv(\"./data/fluorescein/color_spaces_variance_results.csv\", index=False)\n",
    "display(df.head())\n",
    "print(\"--- All files analyzed ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Bin experimental photographs into 1mm x 1mm segments. This is done to normalize between photos that are a different number of pixels wide. Each bin is represented by the mean saturation value (S) of all pixels within that 1mm x 1mm segment. Save these reduced data files into a new folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binned_means(array, xbins=80, ybins=30):\n",
    "    ''' Return the mean value of all numbers \n",
    "        binned into the specied number of bins '''\n",
    "    height, width = array.shape\n",
    "    xbin_indices = np.linspace(0, width, xbins+1)\n",
    "    ybin_indices = np.linspace(0, height, ybins+1)\n",
    "    xbin_indices = [int(x) for x in xbin_indices]\n",
    "    ybin_indices = [int(x) for x in ybin_indices]\n",
    "    count = 0\n",
    "    means = []\n",
    "    for y in range(len(ybin_indices)-1):\n",
    "        temp_row = []\n",
    "        for x in range(len(xbin_indices)-1):\n",
    "            yindex = ybin_indices[y]\n",
    "            n_yindex = ybin_indices[y+1]\n",
    "            xindex = xbin_indices[x]\n",
    "            n_xindex = xbin_indices[x+1]\n",
    "            temp_bin = array[yindex:n_yindex, xindex:n_xindex]\n",
    "            count += temp_bin.size\n",
    "            temp_row.append(np.mean(temp_bin))\n",
    "        means.append(temp_row)\n",
    "        \n",
    "    # Check that all values in image were sampled in mean calculation\n",
    "    assert count == array.size \n",
    "    \n",
    "    # Check that array is the right size\n",
    "    assert len(means) == ybins\n",
    "    assert len(means[0]) == xbins\n",
    "    \n",
    "    return means\n",
    "\n",
    "names = glob.glob(\"./data/fluorescein/experiments/*/crop_*/*.jpg\")\n",
    "\n",
    "for name in names: \n",
    "    image = cv2.imread(name)\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    s = hsv[:,:,1]\n",
    "    binned = binned_means(s, xbins=80, ybins=30)\n",
    "    bin_df = pd.DataFrame(binned)\n",
    "\n",
    "    name_id = name.split(\"/\")[-1].split(\"\\\\\")[-1].split(\".jpg\")[0]\n",
    "    name_type = name_id.split(\"-\")[-1].split(\".jpg\")[0]\n",
    "    name_top = name_id.split(\"-\")[0]+\"-experiment-\"+name_id.split(\"-\")[1]\n",
    "    savename = \"./data/fluorescein/experiments/\"+name_top+\"/1mm_csv_\"+name_type+\"s/\"+name_id+\".csv\"\n",
    "\n",
    "    bin_df.to_csv(savename, index=None, header=False)\n",
    "\n",
    "print(\"--- All files analyzed ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Subtract the Saturation value in the blank image from the corresponding experiment image for each experiment series. This is done to correct for potential differences in lighting between photographs or experiments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = glob.glob(\"./data/fluorescein/experiments/*experiment*/1mm_csv_experiments/*.csv\")\n",
    "\n",
    "for name in names: \n",
    "    try:\n",
    "        name_id = name.split(\"/\")[-1].split(\"\\\\\")[-1].split(\".csv\")[0]\n",
    "        name_num = name_id.split(\"-cropped\")[0]\n",
    "        name_type = name_id.split(\"-\")[-1].split(\".csv\")[0]\n",
    "        name_top = name_id.split(\"-\")[0]+\"-experiment-\"+name_id.split(\"-\")[1]\n",
    "        \n",
    "        std_name = \"./data/fluorescein/experiments/\"+name_top+\"/1mm_csv_standards/\"+name_num+\"-cropped-standard.csv\"\n",
    "        savename = \"./data/fluorescein/experiments/\"+name_top+\"/1mm_csv_differences/\"+name_num+\"-difference.csv\"\n",
    "        \n",
    "        exp_df = pd.read_csv(name, header=None)\n",
    "        std_df = pd.read_csv(std_name, header=None)\n",
    "        exp = np.array(exp_df.values)\n",
    "        std = np.array(std_df.values)\n",
    "\n",
    "        # Check that the two dataframes are the same shape\n",
    "        assert exp_df.shape == std_df.shape\n",
    "        diff = exp-std\n",
    "\n",
    "        # Check that the output is the same size as the input\n",
    "        diff_df = pd.DataFrame(diff)\n",
    "        assert diff_df.shape == exp_df.shape\n",
    "\n",
    "        diff_df.to_csv(savename, index=None, header=False)\n",
    "    except:\n",
    "        print(exp_name)\n",
    "\n",
    "print(\"--- All files analyzed ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Similarly, subtract the Saturation value in the blank image from the corresponding experiment image for each standardization image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = glob.glob(\"./data/fluorescein/standards/1mm_csv_experiments/*.csv\")\n",
    "\n",
    "for name in names: \n",
    "    try:\n",
    "        name_id = name.split(\"/\")[-1].split(\"\\\\\")[-1].split(\"_experiment.csv\")[0]\n",
    "        std_name = \"./data/fluorescein/standards/1mm_csv_standards/\"+name_id+\"_standard.csv\"\n",
    "        savename = \"./data/fluorescein/standards/1mm_csv_differences/\"+name_id+\"_difference.csv\"\n",
    "        \n",
    "        exp_df = pd.read_csv(name, header=None)\n",
    "        std_df = pd.read_csv(std_name, header=None)\n",
    "        exp = np.array(exp_df.values)\n",
    "        std = np.array(std_df.values)\n",
    "\n",
    "        # Check that the two dataframes are the same shape\n",
    "        assert exp_df.shape == std_df.shape\n",
    "        diff = exp-std\n",
    "\n",
    "        # Check that the output is the same size as the input\n",
    "        diff_df = pd.DataFrame(diff)\n",
    "        assert diff_df.shape == exp_df.shape\n",
    "\n",
    "        diff_df.to_csv(savename, index=None, header=False)\n",
    "    except:\n",
    "        print(exp_name)\n",
    "\n",
    "print(\"--- All files analyzed ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Combine the data from all 1mm x 1mm cells for all standardization images into a single file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concentrations = [0.1, 0.5, 0, 1, 2, 3, 4, 5, 10, 15, 20, 25, 50, 100]\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for c in concentrations:\n",
    "    label = str(c).replace(\".\", \"_\")\n",
    "    fname = \"./data/fluorescein/standards/1mm_csv_differences/\"+label+\"_difference.csv\"\n",
    "    temp = pd.read_csv(fname, header=None)\n",
    "    flat = temp.values.flatten()\n",
    "    df[c] = flat\n",
    "    \n",
    "display(df.describe())\n",
    "df.to_csv(\"./data/fluorescein/standardization_saturation_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a master dataframe of statistics for the standardization dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/fluorescein/standardization_saturation_results.csv\")\n",
    "stats_df = df.std(axis=0).reset_index(name='std')\n",
    "stats_df.columns = [\"concentration\", \"std_dev\"]\n",
    "stats_df[\"mean\"] = df.mean(axis=0).values\n",
    "stats_df[\"std_err\"] = df.sem(axis=0).values\n",
    "stats_df.to_csv(\"./data/fluorescein/standardization_saturation_stats.csv\", index=False)\n",
    "stats_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a threshold of concentration for the experimental dataset to use as the 100% dye value in mapping concentration. This is done because the amount of fluorescein observable at the maximum concentration is unknown. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_interp(vals, interp, xmin, xmax):\n",
    "    ''' Return the predicted concentration values (0-100) based on color (S) '''\n",
    "    # Set interpolation value to be within range of standardization dataset\n",
    "    vals = [min(xmax, val) for val in vals]\n",
    "    vals = [max(xmin, val) for val in vals]\n",
    "    \n",
    "    # Set maximum values to be between range specified by ymin and ymax\n",
    "    guess = interp(vals)\n",
    "    return(guess)\n",
    "\n",
    "fnames = glob.glob(\"./data/fluorescein/experiments/*experiment*/1mm_csv_differences/*-00-00-difference.csv\")\n",
    "df = pd.read_csv(\"./data/fluorescein/standardization_saturation_stats.csv\")\n",
    "xmin, xmax = df[\"mean\"].min(), df[\"mean\"].max()\n",
    "interp = scipy.interpolate.interp1d(df[\"mean\"], df[\"concentration\"])\n",
    "values = []\n",
    "\n",
    "for name in fnames:\n",
    "    temp = pd.read_csv(name, header=None)\n",
    "    temp_s = temp.apply(get_interp, args=(interp, xmin, xmax), axis=1)\n",
    "    v = np.array(temp_s.values.tolist()).flatten()\n",
    "    values.append(v)\n",
    "    \n",
    "# Turn into list to pass to histogram matplotlib\n",
    "values = np.array(values).flatten()\n",
    "value_df = pd.DataFrame({\"values_0min\":values})\n",
    "value_df.to_csv(\"./data/fluorescein/0min_concentration_values_cutoff_calculation.csv\", index=False)\n",
    "\n",
    "# Make sure that all values are represented\n",
    "assert values.shape[0] == len(fnames)*80*30\n",
    "cutoff_percent = 0.95\n",
    "\n",
    "value_sort = sorted(values)\n",
    "cutoff_index = int(len(value_sort)*cutoff_percent)\n",
    "print(value_sort[cutoff_index], \"concentration (AU) to use to threshold images\")\n",
    "\n",
    "save_df = pd.DataFrame({\"cutoff_concentration\":[value_sort[cutoff_index]], \"n_bin_samples\":[len(value_sort)],\n",
    "                        \"max_data\":[max(values)], \"min_data\":[min(values)], \"cutoff_percent\":[cutoff_percent]})\n",
    "save_df.to_csv(\"./data/fluorescein/cutoff_concentration.csv\", index=False)\n",
    "display(save_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a linear interpolation between color (HSV saturation) and concentration using the reference dataset\n",
    "- Use the interpolation between color and concentration to map each experimental saturation value to concentration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_interp_bounded(vals, interp, xmin, xmax, ymin, ymax):\n",
    "    ''' Return the predicted concentration values (0-100) based on color (S) '''\n",
    "    # Set interpolation value to be within range of standardization dataset\n",
    "    vals = [min(xmax, val) for val in vals]\n",
    "    vals = [max(xmin, val) for val in vals]\n",
    "    \n",
    "    # Set maximum values to be between range specified by ymin and ymax\n",
    "    guess = interp(vals)\n",
    "    guess = [min(ymax, y) for y in guess]\n",
    "    guess = [max(ymin, y) for y in guess]\n",
    "    \n",
    "    # Set interpolated value to be percentage of range in ymin and ymax\n",
    "    data_range = ymax-ymin\n",
    "    low_threshold = [y-ymin for y in guess]\n",
    "    percentages = [100*y/data_range for y in low_threshold]\n",
    "    \n",
    "    return(percentages)\n",
    "\n",
    "df = pd.read_csv(\"./data/fluorescein/standardization_saturation_stats.csv\")\n",
    "xmin, xmax = df[\"mean\"].min(), df[\"mean\"].max()\n",
    "interp = scipy.interpolate.interp1d(df[\"mean\"], df[\"concentration\"])\n",
    "y_df = pd.read_csv(\"./data/fluorescein/cutoff_concentration.csv\")\n",
    "ymin = y_df[\"min_data\"].values[0]\n",
    "ymax = y_df[\"cutoff_concentration\"].values[0]\n",
    "print(\"Y-min:\",ymin, \"Y-max:\",ymax, \"X-min:\",xmin, \"X-max:\",xmax)\n",
    "\n",
    "names = glob.glob(\"./data/fluorescein/experiments/*experiment*/1mm_csv_differences/*.csv\")\n",
    "for name in names:\n",
    "    temp = pd.read_csv(name, header=None)\n",
    "    temp_s = temp.apply(get_interp_bounded, args=(interp, xmin, xmax, ymin, ymax), axis=0)\n",
    "    \n",
    "    name_date = name.split(\"/\")[-1].split(\"\\\\\")[-1].split(\"-\")[0]\n",
    "    name_exp = name.split(\"/\")[-1].split(\"\\\\\")[-1].split(\"-\")[1]\n",
    "    name_file = name.split(\"/\")[-1].split(\"\\\\\")[-1].split(\"-difference\")[0]\n",
    "\n",
    "    savename = \"./data/fluorescein/experiments/\"+name_date+\"-experiment-\"\\\n",
    "            +name_exp+\"/1mm_csv_concentrations/\"+name_file+\"_concentrations.csv\"\n",
    "    temp_s.to_csv(savename, index=False, header=False)\n",
    "    \n",
    "print(\"--- All files analyzed ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Average the concentration calculations for every time unit (1min, 2min, etc) across all 10 experiments with larvae \n",
    "- Average the concentration calculations for every time unit across all 10 experiments without larvae "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/fluorescein/files_larvae.csv\")\n",
    "larvae = df[\"larvae_experiments\"].values\n",
    "no_larvae = df[\"no_larvae_experiments\"].values\n",
    "\n",
    "times = ['00-00', '01-00', '02-00', '03-00', '04-00', '05-00', \n",
    "         '06-00', '07-00', '08-00', '09-00', '10-00', '11-00',\n",
    "         '12-00', '13-00', '14-00', '15-00', 'ss-ss']\n",
    "\n",
    "animal_dict = {\"no_larvae\":no_larvae, \"larvae\":larvae}\n",
    "\n",
    "for label, animals in animal_dict.items():\n",
    "    for time in times: \n",
    "        timedf = np.zeros((30, 80))\n",
    "        timename = \"./data/fluorescein/experiments/\"+label+\"_averages_1mm/\"+time+\"_averages.csv\"\n",
    "        for animal in animals:\n",
    "            a0, a1 = animal.split(\"-\")[0], animal.split(\"-\")[-1]\n",
    "            readname = \"./data/fluorescein/experiments/\"+animal+\"/1mm_csv_concentrations/\"+ \\\n",
    "                       a0+\"-\"+a1+\"-\"+time+\"_concentrations.csv\"\n",
    "            df = pd.read_csv(readname, header=None)\n",
    "            exp = np.array(df.values)\n",
    "\n",
    "            # Check that the two dataframes are the same shape\n",
    "            assert exp.shape == timedf.shape\n",
    "            timedf = timedf + exp\n",
    "\n",
    "            # Check that the output is the same size as the input\n",
    "            diff_df = pd.DataFrame(diff)\n",
    "            assert diff_df.shape == exp_df.shape\n",
    "        \n",
    "        timedf = timedf / len(animals)\n",
    "        timedf = pd.DataFrame(timedf)\n",
    "        timedf.to_csv(timename, index=False, header=False)\n",
    "        \n",
    "print(\"--- All files analyzed ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a master dataframe containing the concentration in each bin across all 15 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_dict = {0:'00-00', 120:'01-00', 240:'02-00', 360:'03-00', 480:'04-00', 600:'05-00', \n",
    "             720:'06-00', 840:'07-00', 960:'08-00', 1080:'09-00', 1200:'10-00', 1320:'11-00',\n",
    "             1440:'12-00', 1560:'13-00', 1680:'14-00', 1800:'15-00'}\n",
    "\n",
    "bin_ids = np.arange(0, 80*30, 1)\n",
    "bin_ids = [\"bin_\"+str(int(x)) for x in bin_ids]\n",
    "bin_df = pd.DataFrame(index=time_dict.keys(), columns=bin_ids)\n",
    "bin_df.index.name = \"frames\"\n",
    "\n",
    "for larva in [\"larvae\", \"no_larvae\"]:\n",
    "    for time, name in time_dict.items():\n",
    "        name = './data/fluorescein/experiments/'+larva+'_averages_1mm/'+name+'_averages.csv'\n",
    "        # Round values to 2 decimal points so file is not huge\n",
    "        df = pd.read_csv(name, header=None).round(2)\n",
    "        array = np.array(df.values)\n",
    "        rows, columns = array.shape[0], array.shape[1]\n",
    "        for row in range(rows):\n",
    "            for column in range(columns):\n",
    "                ID = 'bin_' + str(row*80 + column)\n",
    "                bin_df.loc[time, ID] = array[row][column]\n",
    "\n",
    "    display(bin_df.head())\n",
    "    bin_df.to_csv(\"./data/fluorescein/bin_concentration_by_time_\"+larva+\".csv\")\n",
    "print(\"--- All files analyzed ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a file containing distances of all bins from the odor source for experiments with larvae (for use in computational modeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/fluorescein/files_larvae.csv\")\n",
    "larvae = df[\"larvae_experiments\"].values\n",
    "print(len(larvae) == 10) # There should be 10 experiments with larvae\n",
    "\n",
    "pairs = []\n",
    "for larva in larvae[0:1]:\n",
    "    a0, a1 = larva.split(\"-\")[0], larva.split(\"-\")[-1]\n",
    "    name = \"./data/fluorescein/experiments/\"+larva+\"/1mm_csv_concentrations/\"+ \\\n",
    "                       a0+\"-\"+a1+\"-00-00_concentrations.csv\"\n",
    "    \n",
    "    df = pd.read_csv(name, header=None)\n",
    "    array = np.array(df.values)\n",
    "    rows, columns = array.shape[0], array.shape[1]\n",
    "    for row in range(rows):\n",
    "        for column in range(columns):\n",
    "            distance = np.hypot(row, column)\n",
    "            value = array[row][column]\n",
    "            pairs.append([distance, array[row][column]])\n",
    "            \n",
    "pair_df = pd.DataFrame(pairs, columns = [\"distance_mm\", \"concentration\"])\n",
    "pair_df.to_csv(\"./data/fluorescein/distance_concentration_map.csv\", index=None)\n",
    "display(pair_df.tail())\n",
    "print(\"--- All files analyzed ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create files to analyze differences in diffusion between experiments with and without larvae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/fluorescein/files_larvae.csv\")\n",
    "larvae = df[\"larvae_experiments\"].values\n",
    "no_larvae = df[\"no_larvae_experiments\"].values\n",
    "\n",
    "times = ['00-00', '01-00', '02-00', '03-00', '04-00', '05-00', \n",
    "         '06-00', '07-00', '08-00', '09-00', '10-00', '11-00',\n",
    "         '12-00', '13-00', '14-00', '15-00']\n",
    "\n",
    "animal_dict = {\"no_larvae\":no_larvae, \"larvae\":larvae}\n",
    "timevals = []\n",
    "\n",
    "for label, animals in animal_dict.items():\n",
    "    for time in times: \n",
    "        for animal in animals:\n",
    "            a0, a1 = animal.split(\"-\")[0], animal.split(\"-\")[-1]\n",
    "            readname = \"./data/fluorescein/experiments/\"+animal+\"/1mm_csv_concentrations/\"+ \\\n",
    "                       a0+\"-\"+a1+\"-\"+time+\"_concentrations.csv\"\n",
    "            df = pd.read_csv(readname, header=None)\n",
    "            array = np.array(df.values)\n",
    "            vals = array.flatten()\n",
    "            perc = sum(i > 50 for i in vals)/len(vals)\n",
    "            timevals.append([time, perc, label])\n",
    "            \n",
    "timeval_df = pd.DataFrame(timevals, columns = [\"time\", \"perc_over_50\", \"larva_presence\"])\n",
    "timeval_df[\"time\"] = timeval_df[\"time\"].str.replace(\"-00\", \"\").astype(float)\n",
    "timeval_df.to_csv(\"./data/fluorescein/larvae_no_larvae_comparison.csv\", index=None)\n",
    "display(timeval_df.tail())\n",
    "print(len(timeval_df)/16 == 20) # Should be 20 experiments - 10 larvae and 10 without larvae\n",
    "print(\"--- All files analyzed ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fit an exponential line to the distance and concentration dataset for modeling purposes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/fluorescein/distance_concentration_map.csv\")\n",
    "\n",
    "df = df[df[\"distance_mm\"] > 0]\n",
    "df = df[df['concentration'] > 0]\n",
    "x = df[\"distance_mm\"]\n",
    "y = df[\"concentration\"]\n",
    "\n",
    "# BLUE: EXPONENTIAL SCALE\n",
    "a, b = np.polyfit(x, np.log(y), 1)\n",
    "print(\"A:\", a, \"B:\", b)\n",
    "\n",
    "proc_50 = (np.log(50)-b)/a\n",
    "print(\"Distance where concentration is 50%:\", proc_50)\n",
    "\n",
    "df[\"ln_conc\"] = np.log(df[\"concentration\"]) # In numpy log is natural log\n",
    "df.to_csv(\"./data/fluorescein/distance_concentration_map_fitted.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
