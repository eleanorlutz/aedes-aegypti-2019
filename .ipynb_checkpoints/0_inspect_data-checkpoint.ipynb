{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect data\n",
    "#### List of tasks accomplished in this Jupyter Notebook:\n",
    "- Remove dead larvae and experiments that were accidentally begun before the larval daylight cycle. \n",
    "- Convert experiment start time to number of minutes elapsed since light cycle ON time\n",
    "- Save cleaned dataset in a new `CSV` file. \n",
    "- Check that the number of fed and starved animals in each experiment adds up to the total number of animals. \n",
    "- Output the number of animals in each experiment (total) and the number of fed and starved animals for each experiment as a TXT file\n",
    "- Check that each experiment larva has one video HDF5 file and one folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob, os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Remove dead larvae and experiments that were accidentally begun before the larval daylight cycle. \n",
    "- Convert experiment start time to number of minutes elapsed since light cycle ON time\n",
    "- Save cleaned dataset in a new `CSV` file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "540 total larvae experiments\n",
      "503 larvae after removing dead larvae\n",
      "499 larvae after removing experiments not during daylight\n",
      "--- Data cleaned and saved to file ---\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./data/experiment_IDs/static_data_naive.csv')\n",
    "print(len(df), \"total larvae experiments\")\n",
    "\n",
    "no_dead = df[df['dead'] == 'no'].copy()\n",
    "print(len(no_dead), \"larvae after removing dead larvae\")\n",
    "\n",
    "no_dead[\"start_hour\"] = pd.DatetimeIndex(no_dead['acclimate_start']).hour\n",
    "no_dead[\"start_min\"] = pd.DatetimeIndex(no_dead['acclimate_start']).minute\n",
    "\n",
    "# Remove experiments starting before 9am\n",
    "times = no_dead[no_dead[\"start_hour\"] >= 9]\n",
    "\n",
    "# Remove experiments starting after \n",
    "times = times[(times[\"start_hour\"] <= 9+11) | \\\n",
    "              ((times[\"start_hour\"] <= 9+12) & (times[\"start_min\"] <= 45))]\n",
    "print(len(times), \"larvae after removing experiments not during daylight\")\n",
    "\n",
    "times[\"minutes_past_L\"] = pd.to_datetime(\"2018-01-01\"+times[\"experiment_start\"], format=\"%Y-%m-%d%H:%M\")\n",
    "times[\"minutes_past_L\"] = times[\"minutes_past_L\"] - pd.to_datetime(\"2018-01-01-09:00:00\")\n",
    "times[\"minutes_past_L\"] = pd.DatetimeIndex(times[\"minutes_past_L\"]).hour * 60 + \\\n",
    "                            pd.DatetimeIndex(times[\"minutes_past_L\"]).minute\n",
    "\n",
    "times.to_csv(\"./data/experiment_IDs/cleaned_static_data.csv\", index=None)\n",
    "print(\"--- Data cleaned and saved to file ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check that the number of fed and starved animals in each experiment adds up to the total number of animals. \n",
    "- Output the number of animals in each experiment (total) and the number of fed and starved animals for each experiment as a TXT file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Data summary values saved to file ---\n"
     ]
    }
   ],
   "source": [
    "# READ IN CLEANED DATASET\n",
    "df = pd.read_csv(\"./data/experiment_IDs/cleaned_static_data.csv\")\n",
    "textfile = [str(len(df))+\" Total larvae in entire dataset\"]\n",
    "\n",
    "num_s = len(df[df[\"starved\"] == '1day'])\n",
    "num_f = len(df[df[\"starved\"] == 'no'])\n",
    "textfile.append(str(num_s)+\" Starved larvae in entire dataset\")\n",
    "textfile.append(str(num_f)+\" Fed larvae in entire dataset\")\n",
    "textfile.append('---')  \n",
    "\n",
    "# Check that number of fed and starved animals adds up to the total\n",
    "assert len(df) == num_s + num_f\n",
    "\n",
    "experiments = df[\"treatment_odor\"].unique()\n",
    "for experiment in experiments:\n",
    "    temp = df[df[\"treatment_odor\"] == experiment]\n",
    "    temp_starved = temp[temp[\"starved\"] == '1day']\n",
    "    temp_fed = temp[temp[\"starved\"] == 'no']\n",
    "    \n",
    "    # Check that number of fed and starved animals adds up to the total\n",
    "    assert len(temp) == len(temp_fed) + len(temp_starved)\n",
    "    \n",
    "    textfile.append(experiment.upper())\n",
    "    textfile.append(str(len(temp))+\" Total larvae\")\n",
    "    textfile.append(str(len(temp_starved))+\" Starved larvae\")\n",
    "    textfile.append(str(len(temp_fed))+\" Fed larvae\")\n",
    "    textfile.append('---')\n",
    "    \n",
    "text_df = pd.DataFrame(textfile)\n",
    "text_df.to_csv(\"./data/experiment_IDs/n_values.csv\", header=None, index=None)\n",
    "print(\"--- Data summary values saved to file ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check that each experiment larva has one video HDF5 file and one folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- All checks passed ---\n"
     ]
    }
   ],
   "source": [
    "# READ IN CLEANED DATASET\n",
    "df = pd.read_csv(\"./data/experiment_IDs/cleaned_static_data.csv\")\n",
    "animals = df[\"animal_ID\"].values\n",
    "\n",
    "# Create folder names for each animal ID to use in checking\n",
    "df[\"acc_filenames\"] = \"./data/trajectories/video_csvs/\"+df[\"animal_ID\"]+\"-acclimate.csv\"\n",
    "df[\"exp_filenames\"] = \"./data/trajectories/video_csvs/\"+df[\"animal_ID\"]+\"-experiment.csv\"\n",
    "\n",
    "acc_fnames = df[\"acc_filenames\"].values\n",
    "exp_fnames = df[\"exp_filenames\"].values\n",
    "\n",
    "# Check that every animal ID is unique\n",
    "assert len(set(acc_fnames)) == len(acc_fnames)\n",
    "assert len(set(exp_fnames)) == len(exp_fnames)\n",
    "\n",
    "# Check that each animal has 1 and only 1 file associated with the animal\n",
    "accs = glob.glob('./data/trajectories/video_csvs/*-acclimate.csv')\n",
    "exps = glob.glob('./data/trajectories/video_csvs/*-experiment.csv')\n",
    "\n",
    "assert sorted(acc_fnames) == sorted(accs)\n",
    "assert sorted(exp_fnames) == sorted(exps)\n",
    "\n",
    "# CHECK THAT MANUALLY ANNOTATED FILES ALL EXIST AND ARE SPELLED CORRECTLY\n",
    "df = pd.read_csv(\"./data/trajectories/manually_checked_beginning_pause.csv\")\n",
    "\n",
    "for name in df[\"filename\"].values:\n",
    "    fname = \"./data/trajectories/video_csvs/\"+name+\".csv\"\n",
    "    if not os.path.isfile(fname):\n",
    "        print(fname)\n",
    "        \n",
    "print(\"--- All checks passed ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499 cleaned animal IDs to analyze\n",
      "---\n",
      "0 acclimate and 0 experiment videos included that are not valid larvae (2018).\n",
      "0 acclimate and 0 missing videos (2018).\n",
      "---\n",
      "0 acclimate and 0 experiment videos included that are not valid larvae (2017).\n",
      "0 acclimate and 0 missing videos (2017).\n",
      "---\n",
      "0 acclimate and 0 experiment videos included that are not valid larvae (2019).\n",
      "0 acclimate and 0 missing videos (2019).\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# READ IN CLEANED DATASET AND TEST THAT ALL FILES EXIST FOR DATA DRYAD UPLOAD\n",
    "df = pd.read_csv(\"./data/experiment_IDs/cleaned_static_data.csv\")\n",
    "print(len(df), 'cleaned animal IDs to analyze\\n---')\n",
    "\n",
    "# Print out the files in the video folders that are not necessary\n",
    "# These belong to dead larvae or those pupated before the end of the experiment\n",
    "\n",
    "# 2018\n",
    "df = pd.read_csv(\"./data/experiment_IDs/cleaned_static_data.csv\")\n",
    "df = df[df['animal_ID'].str.startswith('18')]\n",
    "df[\"acc_filenames\"] = \"/home/eleanor/Downloads/videos/\"+df[\"animal_ID\"]+\"-acclimate.avi\"\n",
    "df[\"exp_filenames\"] = \"/home/eleanor/Downloads/videos/\"+df[\"animal_ID\"]+\"-experiment.avi\"\n",
    "acc_fnames = df[\"acc_filenames\"].values\n",
    "exp_fnames = df[\"exp_filenames\"].values\n",
    "acc_fs = glob.glob('/home/eleanor/Downloads/videos/18*-acclimate.avi')\n",
    "exp_fs = glob.glob('/home/eleanor/Downloads/videos/18*-experiment.avi')\n",
    "a_missing = [x for x in acc_fs if x not in acc_fnames]\n",
    "e_missing = [x for x in exp_fs if x not in exp_fnames]\n",
    "print(len(a_missing), 'acclimate and', len(e_missing), 'experiment videos included that are not valid larvae (2018).')\n",
    "for a in sorted(a_missing):\n",
    "    print(a)\n",
    "a_missing = [x for x in acc_fnames if x not in acc_fs]\n",
    "e_missing = [x for x in exp_fnames if x not in exp_fs]\n",
    "print(len(a_missing), 'acclimate and', len(e_missing), 'missing videos (2018).\\n---')\n",
    "for a in sorted(a_missing):\n",
    "    print(a)\n",
    "    \n",
    "# 2017\n",
    "df = pd.read_csv(\"./data/experiment_IDs/cleaned_static_data.csv\")\n",
    "df = df[df['animal_ID'].str.startswith('17')]\n",
    "df[\"acc_filenames\"] = \"/home/eleanor/Downloads/videos/\"+df[\"animal_ID\"]+\"-acclimate.avi\"\n",
    "df[\"exp_filenames\"] = \"/home/eleanor/Downloads/videos/\"+df[\"animal_ID\"]+\"-experiment.avi\"\n",
    "acc_fnames = df[\"acc_filenames\"].values\n",
    "exp_fnames = df[\"exp_filenames\"].values\n",
    "acc_fs = glob.glob('/home/eleanor/Downloads/videos/17*-acclimate.avi')\n",
    "exp_fs = glob.glob('/home/eleanor/Downloads/videos/17*-experiment.avi')\n",
    "a_missing = [x for x in acc_fs if x not in acc_fnames]\n",
    "e_missing = [x for x in exp_fs if x not in exp_fnames]\n",
    "print(len(a_missing), 'acclimate and', len(e_missing), 'experiment videos included that are not valid larvae (2017).')\n",
    "for a in sorted(e_missing):\n",
    "    print(a)\n",
    "a_missing = [x for x in acc_fnames if x not in acc_fs]\n",
    "e_missing = [x for x in exp_fnames if x not in exp_fs]\n",
    "print(len(a_missing), 'acclimate and', len(e_missing), 'missing videos (2017).\\n---')\n",
    "for a in sorted(a_missing):\n",
    "    print(a)\n",
    "    \n",
    "# 2019\n",
    "df = pd.read_csv(\"./data/experiment_IDs/cleaned_static_data.csv\")\n",
    "df = df[df['animal_ID'].str.startswith('19')]\n",
    "df['dat'] = df['animal_ID'].str[0:6]\n",
    "df['num'] = df['animal_ID'].str[7:9]\n",
    "df['pos'] = df['animal_ID'].str[10:]\n",
    "df[\"acc_filenames\"] = \"/home/eleanor/Downloads/videos/\"+df['dat']+'-'+df['num']+'-'+\"A\"+'-'+df['pos']+'.avi'\n",
    "df[\"exp_filenames\"] = \"/home/eleanor/Downloads/videos/\"+df['dat']+'-'+df['num']+'-'+\"E\"+'-'+df['pos']+'.avi'\n",
    "acc_fnames = df[\"acc_filenames\"].values\n",
    "exp_fnames = df[\"exp_filenames\"].values\n",
    "acc_fs = glob.glob('/home/eleanor/Downloads/videos/19*A*.avi')\n",
    "exp_fs = glob.glob('/home/eleanor/Downloads/videos/19*E*.avi')\n",
    "a_missing = [x for x in acc_fs if x not in acc_fnames]\n",
    "e_missing = [x for x in exp_fs if x not in exp_fnames]\n",
    "print(len(a_missing), 'acclimate and', len(e_missing), 'experiment videos included that are not valid larvae (2019).')\n",
    "for a in sorted(a_missing):\n",
    "    print(a)\n",
    "a_missing = [x for x in acc_fnames if x not in acc_fs]\n",
    "e_missing = [x for x in exp_fnames if x not in exp_fs]\n",
    "print(len(a_missing), 'acclimate and', len(e_missing), 'missing videos (2019).\\n---')\n",
    "for a in sorted(a_missing):\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499 cleaned animal IDs to analyze\n",
      "---\n",
      "0 acclimate and 0 experiment files included that are not valid larvae (2018).\n",
      "0 acclimate and 0 missing files (2018).\n",
      "---\n",
      "0 acclimate and 0 experiment files included that are not valid larvae (2017).\n",
      "0 acclimate and 0 missing files (2017).\n",
      "---\n",
      "0 acclimate and 0 experiment files included that are not valid larvae (2019).\n",
      "0 acclimate and 0 missing files (2019).\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# READ IN CLEANED DATASET AND TEST THAT ALL FILES EXIST FOR DATA DRYAD UPLOAD\n",
    "df = pd.read_csv(\"./data/experiment_IDs/cleaned_static_data.csv\")\n",
    "print(len(df), 'cleaned animal IDs to analyze\\n---')\n",
    "\n",
    "# Print out the files in the video folders that are not necessary\n",
    "# These belong to dead larvae or those pupated before the end of the experiment\n",
    "\n",
    "# 2018\n",
    "df = pd.read_csv(\"./data/experiment_IDs/cleaned_static_data.csv\")\n",
    "df = df[df['animal_ID'].str.startswith('18')]\n",
    "df[\"acc_filenames\"] = \"/home/eleanor/Downloads/analysis_files_reviewed/\"+df[\"animal_ID\"]+\"-acclimate\"\n",
    "df[\"exp_filenames\"] = \"/home/eleanor/Downloads/analysis_files_reviewed/\"+df[\"animal_ID\"]+\"-experiment\"\n",
    "acc_fnames = df[\"acc_filenames\"].values\n",
    "exp_fnames = df[\"exp_filenames\"].values\n",
    "acc_fs = glob.glob('/home/eleanor/Downloads/analysis_files_reviewed/18*-acclimate')\n",
    "exp_fs = glob.glob('/home/eleanor/Downloads/analysis_files_reviewed/18*-experiment')\n",
    "a_missing = [x for x in acc_fs if x not in acc_fnames]\n",
    "e_missing = [x for x in exp_fs if x not in exp_fnames]\n",
    "print(len(a_missing), 'acclimate and', len(e_missing), 'experiment files included that are not valid larvae (2018).')\n",
    "for a in sorted(a_missing):\n",
    "    print(a)\n",
    "a_missing = [x for x in acc_fnames if x not in acc_fs]\n",
    "e_missing = [x for x in exp_fnames if x not in exp_fs]\n",
    "print(len(a_missing), 'acclimate and', len(e_missing), 'missing files (2018).\\n---')\n",
    "for a in sorted(a_missing):\n",
    "    print(a)\n",
    "    \n",
    "# 2017\n",
    "df = pd.read_csv(\"./data/experiment_IDs/cleaned_static_data.csv\")\n",
    "df = df[df['animal_ID'].str.startswith('17')]\n",
    "df[\"acc_filenames\"] = \"/home/eleanor/Downloads/analysis_files_reviewed/\"+df[\"animal_ID\"]+\"-acclimate\"\n",
    "df[\"exp_filenames\"] = \"/home/eleanor/Downloads/analysis_files_reviewed/\"+df[\"animal_ID\"]+\"-experiment\"\n",
    "acc_fnames = df[\"acc_filenames\"].values\n",
    "exp_fnames = df[\"exp_filenames\"].values\n",
    "acc_fs = glob.glob('/home/eleanor/Downloads/analysis_files_reviewed/17*-acclimate')\n",
    "exp_fs = glob.glob('/home/eleanor/Downloads/analysis_files_reviewed/17*-experiment')\n",
    "a_missing = [x for x in acc_fs if x not in acc_fnames]\n",
    "e_missing = [x for x in exp_fs if x not in exp_fnames]\n",
    "print(len(a_missing), 'acclimate and', len(e_missing), 'experiment files included that are not valid larvae (2017).')\n",
    "for a in sorted(e_missing):\n",
    "    print(a)\n",
    "a_missing = [x for x in acc_fnames if x not in acc_fs]\n",
    "e_missing = [x for x in exp_fnames if x not in exp_fs]\n",
    "print(len(a_missing), 'acclimate and', len(e_missing), 'missing files (2017).\\n---')\n",
    "for a in sorted(a_missing):\n",
    "    print(a)\n",
    "    \n",
    "# 2019\n",
    "df = pd.read_csv(\"./data/experiment_IDs/cleaned_static_data.csv\")\n",
    "df = df[df['animal_ID'].str.startswith('19')]\n",
    "df['dat'] = df['animal_ID'].str[0:6]\n",
    "df['num'] = df['animal_ID'].str[7:9]\n",
    "df['pos'] = df['animal_ID'].str[10:]\n",
    "df[\"acc_filenames\"] = \"/home/eleanor/Downloads/analysis_files_reviewed/\"+df['dat']+'-'+df['num']+'-'+\"A\"+'-'+df['pos']\n",
    "df[\"exp_filenames\"] = \"/home/eleanor/Downloads/analysis_files_reviewed/\"+df['dat']+'-'+df['num']+'-'+\"E\"+'-'+df['pos']\n",
    "acc_fnames = df[\"acc_filenames\"].values\n",
    "exp_fnames = df[\"exp_filenames\"].values\n",
    "acc_fs = glob.glob('/home/eleanor/Downloads/analysis_files_reviewed/19*A*')\n",
    "exp_fs = glob.glob('/home/eleanor/Downloads/analysis_files_reviewed/19*E*')\n",
    "a_missing = [x for x in acc_fs if x not in acc_fnames]\n",
    "e_missing = [x for x in exp_fs if x not in exp_fnames]\n",
    "print(len(a_missing), 'acclimate and', len(e_missing), 'experiment files included that are not valid larvae (2019).')\n",
    "for a in sorted(e_missing):\n",
    "    print(a)\n",
    "a_missing = [x for x in acc_fnames if x not in acc_fs]\n",
    "e_missing = [x for x in exp_fnames if x not in exp_fs]\n",
    "print(len(a_missing), 'acclimate and', len(e_missing), 'missing files (2019).\\n---')\n",
    "for a in sorted(a_missing):\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
